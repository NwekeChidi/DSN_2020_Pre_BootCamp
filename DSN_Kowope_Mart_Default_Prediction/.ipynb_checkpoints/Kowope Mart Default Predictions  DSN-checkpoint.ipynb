{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging Machine learning to predict customers who are likely to default or not.\n",
    "#### There has been recent cases of credit defaults and Kowope Mart will like to have a system that profiles customers who are worthy of the card with minimum if not zero risk of defaulting.\n",
    "\n",
    "# This is Qualification Competition for the Data Science Nigeria AI Bootcamp 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "target = train['default_status']\n",
    "#Submission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing different functions to ensure modularity\n",
    "#\n",
    "class Analyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def check_null(self, data):\n",
    "        \"\"\"This function returns a fraction of the\n",
    "            null values per feature in the data\n",
    "        ** Args: Data - pandas dataframe\n",
    "        ** Return: decimal value - (sum of null values per feature / sum of data points)\n",
    "        \"\"\"\n",
    "        nan_cols = [col for col in data.columns if data[col].isnull().sum() > 0]\n",
    "        print(f\"Shape: {data.shape}, Number of Columns with NaN: {len(nan_cols)}\")\n",
    "        return data[nan_cols].isnull().sum()/data.shape[0]\n",
    "\n",
    "    def plot_feature_importances(self, model, data, num_features=50):\n",
    "        \"\"\"Returns a plot of the feature importance as scored by the model\n",
    "        ** Args: Data - pandas dataframe\n",
    "                 Model - Algorithm\n",
    "        ** Return: bar plot\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(15, 30));\n",
    "        feature_importance_df = pd.DataFrame(gbc.feature_importances_, columns=['Importance'])\n",
    "        feature_importance_df['Feature'] = train_data.columns\n",
    "        sns.barplot(x=\"Importance\", y=\"Features\", data=feature_importance_df.sort_values(by=['Importance'], \n",
    "                                                                               ascending = False).head(num_features))\n",
    "        plt.title(model);\n",
    "\n",
    "\n",
    "    def categorical_plot(self, data, hue, cols=None):\n",
    "        \"\"\"Return a plot of categorical features in a data\n",
    "        ** Args: Data - pandas dataframe\n",
    "                 Hue - string\n",
    "                 Categorical Columns - list\n",
    "        ** Return: bar plot\n",
    "        \"\"\"\n",
    "        if cols == None: cols = [cname for cname in data.columns if data[cname].dtype == 'object' and data[cname].nunique() < 20]\n",
    "        for col in cols: \n",
    "            if col in data.columns:\n",
    "                sns.countplot(y=col, hue=hue, data=data)\n",
    "                plt.show()\n",
    "                \n",
    "    def get_score(self, data, target, model=None, prefit=False):\n",
    "        \"\"\"Returns the auc score of a base model\n",
    "        ** Args: model, data, target\n",
    "        ** Return: auc score - float\n",
    "        \"\"\"\n",
    "        from sklearn.metrics import roc_auc_score, accuracy_score, log_loss\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        x_t, x_v, y_t, y_v = train_test_split(data, target, stratify=target, test_size=0.3, random_state=0)\n",
    "        if model == None:\n",
    "            model = LogisticRegression().fit(x_t, y_t)\n",
    "        if not prefit:\n",
    "            model.fit(x_t, y_t)\n",
    "        train_score = roc_auc_score(y_t, model.predict_proba(x_t)[:,1])\n",
    "        test_score = roc_auc_score(y_v, model.predict_proba(x_v)[:,1])\n",
    "        print(f\"Train Score: {train_score:.4f},    Test Score: {test_score:.4f}\")\n",
    "    \n",
    "    def scale(self, data, target, scale_type='StandardScaler'):\n",
    "        from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        x_t, x_v, y_t, y_v = train_test_split(data, target, stratify=target, test_size=0.3, random_state=0)\n",
    "        ss = StandardScaler()\n",
    "        mm = MinMaxScaler()\n",
    "        rs = RobustScaler()\n",
    "        \n",
    "        def fit_scaler(self, scaler, x_train, x_val):\n",
    "            scaler.fit(x_train)\n",
    "            x_train = scaler.transform(x_train)\n",
    "            x_val = scaler.transform(x_val)\n",
    "            return x_train, x_val\n",
    "        if scale_type == 'StandardScaler':\n",
    "            x_t, x_v = fit_scaler(ss, x_t, x_v)\n",
    "        if scale_type == 'RobustScaler':\n",
    "            x_t, x_v = fit_scaler(rs, x_t, x_v)\n",
    "        else:\n",
    "            x_t, x_v = fit_scaler(mm, x_t, x_v)\n",
    "        return x_t, x_v, y_t, y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = Analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['default_status'] == 'yes', 'default_status'] = 1\n",
    "train.loc[train['default_status'] == 'no', 'default_status'] = 0\n",
    "train['default_status'] = train['default_status'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(20, 15))\n",
    "sns.heatmap(train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column for rows with columns missing\n",
    "train[\"Num_Cols_NaN\"] = train.T.isnull().sum()\n",
    "test[\"Num_Cols_NaN\"] = test.T.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining train and test together to avoid repeated preprocessing\n",
    "\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "all_data = pd.concat([train, test])\n",
    "\n",
    "train.shape, test.shape, all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.check_null(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['avg_risk_factors'] = (all_data['form_field1'].fillna(0) + all_data['form_field2'].fillna(0)) / 2\n",
    "all_data['avg_severity'] = (all_data['form_field3'] + all_data['form_field4'] + all_data['form_field5']) / 3\n",
    "all_data['credit_scale'] = (all_data['form_field6'] + all_data['form_field8']) / 2\n",
    "all_data['avg_tenure'] = (all_data['form_field32'] + all_data['form_field33']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data['def_on_ff1'] = np.NaN\n",
    "for i in range(all_data.shape[0]):\n",
    "    if all_data['form_field1'].iloc[i] <= 3200:\n",
    "        all_data['def_on_ff1'].iloc[i] = 'most default'\n",
    "    elif all_data['form_field1'].iloc[i] > 3200 and all_data['form_field1'].iloc[i] <= 3400:\n",
    "        all_data['def_on_ff1'].iloc[i] = 'more default'\n",
    "    else:\n",
    "        all_data['def_on_ff1'].iloc[i] = 'less default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating columns \n",
    "all_data['def_on_avg'] = np.NaN\n",
    "for i in range(all_data.shape[0]):\n",
    "    if all_data['avg_tenure'].iloc[i] <= 100 or all_data['avg_severity'].iloc[i] > 1 and all_data['def_on_ff1'].iloc[i] != 'less_default':\n",
    "        all_data['def_on_avg'].iloc[i] = 'most often default'\n",
    "    else:\n",
    "        all_data['def_on_avg'].iloc[i] = 'less often default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['form_field32+33'] = all_data['form_field33'] + all_data['form_field32']\n",
    "all_data['form_field6+8'] = all_data['form_field6'] + all_data['form_field8']\n",
    "all_data['form_field17+18'] = all_data['form_field17'] + all_data['form_field18']\n",
    "all_data['form_field19+20'] = all_data['form_field19'] + all_data['form_field20']\n",
    "all_data['form_field4+46'] = all_data['form_field4'] + all_data['form_field46']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.loc[all_data['avg_tenure'] > 150, 'def_on_ten'] = 'active'\n",
    "all_data.loc[all_data['avg_tenure'] <= 150, 'def_on_ten'] = 'less active'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['avg_credit_feats'] = np.NaN\n",
    "pref = np.arange(6,16,1)\n",
    "feats = ['form_field'+str(i) for i in pref]\n",
    "for j in range(all_data.shape[0]):\n",
    "    all_data['avg_credit_feats'].iloc[j] = all_data[feats].iloc[j].sum(axis=0) / len(feats)\n",
    "all_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['avg_card_feats'] = np.NaN\n",
    "pref = np.arange(16,28,1)\n",
    "feats = ['form_field'+str(i) for i in pref]\n",
    "for j in range(all_data.shape[0]):\n",
    "    all_data['avg_card_feats'].iloc[j] = all_data[feats].iloc[j].sum(axis=0) / len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['avg_time_feats'] = np.NaN\n",
    "pref = np.arange(28,40,1)\n",
    "feats = ['form_field'+str(i) for i in pref]\n",
    "for j in range(all_data.shape[0]):\n",
    "    all_data['avg_time_feats'].iloc[j] = all_data[feats].iloc[j].sum(axis=0) / len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['avg_other_feats'] = np.NaN\n",
    "pref = np.arange(42,48,1)\n",
    "feats = ['form_field'+str(i) for i in pref]\n",
    "feats.remove('form_field47')\n",
    "feats.append('form_field50')\n",
    "for j in range(all_data.shape[0]):\n",
    "    all_data['avg_other_feats'].iloc[j] = all_data[feats].iloc[j].sum(axis=0) / len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.categorical_plot(all_data[all_data['is_train']==1], 'default_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving data to avoid repeatedly engineeering each time I restart runtime\n",
    "\n",
    "#all_data.to_csv('all_data44.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_csv('all_data44.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the categorical cols\n",
    "cat_cols = [col for col in all_data.drop(['Applicant_ID'], axis=1)\n",
    "            if all_data[col].dtype == 'object']\n",
    "cat_cols.remove('form_field47')\n",
    "cols_generated = cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****** Encoding the categorical cols *********\n",
    "\n",
    "## One Hot encoding\n",
    "one_hot_cols = [cname for cname in all_data.columns\n",
    "                if all_data[cname].nunique() < 10 and all_data[cname].dtype == 'object']\n",
    "for i in range(len(one_hot_cols)):\n",
    "    all_data = pd.concat( [all_data, pd.get_dummies(all_data[one_hot_cols[i]], prefix='_')], axis=1 )\n",
    "\n",
    "# Label encoding\n",
    "all_data['form_field47'] = all_data['form_field47'].factorize()[0]\n",
    "for i in range(len(cols_generated)):\n",
    "    new_col = cols_generated[i] + '_label'\n",
    "    all_data[new_col] = all_data[cols_generated[i]].factorize()[0]\n",
    "# # cols_generated.append('form_field47')\n",
    "# # all_data = all_data.drop([cols_generated], axis=1)\n",
    "\n",
    "# Count encoding\n",
    "for i in range(len(cols_generated)):\n",
    "    all_data[cols_generated[i]] = all_data[cols_generated[i]].map(all_data[cols_generated[i]].value_counts())\n",
    "    \n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling null values\n",
    "\n",
    "fill_w = ['mean', 'median', 'std', 0, -999]\n",
    "for i in range(len(fill_w)):\n",
    "    target = train['default_status']\n",
    "    train_t = all_data.loc[all_data['is_train']==1].drop(['Applicant_ID', 'default_status',\n",
    "                                                         'form_field40', 'form_field41', \n",
    "                                                          'form_field31', 'is_train',\n",
    "                                                          'form_field48', 'form_field49'], axis=1)\n",
    "    print('filling null with: ', fill_w[i], '.......')\n",
    "    cols = train_t.columns\n",
    "    for j in range(len(cols)):\n",
    "        if fill_w[i] == 'mean':\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(train_t[cols[j]].mean())\n",
    "        elif fill_w[i] == 'median':\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(train_t[cols[j]].median())\n",
    "        elif fill_w[i] == 'std':\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(train_t[cols[j]].std())\n",
    "        else:\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(fill_w[i])\n",
    "    print('Done filling null!')\n",
    "    print('Getting score ......')\n",
    "    tools.get_score(train_t, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling null values\n",
    "catt = CatBoostClassifier(verbose=False)\n",
    "\n",
    "fill_w = ['mean', 'median', 'std', 0, -999]\n",
    "for i in range(len(fill_w)):\n",
    "    target = train['default_status']\n",
    "    train_t = all_data.loc[all_data['is_train']==1].drop(['Applicant_ID', 'default_status',\n",
    "                                                         'form_field40', 'form_field41', \n",
    "                                                          'form_field31', 'is_train',\n",
    "                                                          'form_field48', 'form_field49'], axis=1)\n",
    "    print('filling null with: ', fill_w[i], '.......')\n",
    "    cols = train_t.columns\n",
    "    for j in range(len(cols)):\n",
    "        if fill_w[i] == 'mean':\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(train_t[cols[j]].mean())\n",
    "        elif fill_w[i] == 'median':\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(train_t[cols[j]].median())\n",
    "        elif fill_w[i] == 'std':\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(train_t[cols[j]].std())\n",
    "        else:\n",
    "            train_t[cols[j]] = train_t[cols[j]].fillna(fill_w[i])\n",
    "    print('Done filling null!')\n",
    "    print('Getting score ......')\n",
    "    tools.get_score(train_t, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling null\n",
    "all_data = all_data.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting Data back to train and test\n",
    "target = all_data.loc[all_data['is_train']==1]['default_status']\n",
    "train_data = all_data.loc[all_data['is_train']==1].drop(['Applicant_ID', 'default_status', #'form_field6', 'form_field14',\n",
    "                                                         'form_field40', 'form_field41', #'form_field47',\n",
    "                                                          'form_field31', 'is_train', #'form_field14',\n",
    "                                                          'form_field48', 'form_field49'], axis=1)\n",
    "test_data = all_data.loc[all_data['is_train']==0].drop(['Applicant_ID', 'default_status', #'form_field6', 'form_field14',\n",
    "                                                         'form_field40', 'form_field41', \n",
    "                                                          'form_field31', 'is_train', #'form_field14',\n",
    "                                                          'form_field48', 'form_field49'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Catboost model using Stratified KFold\n",
    "#and making predictions on test data\n",
    "\n",
    "auc_list = list()\n",
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['Applicant_ID'] = test['Applicant_ID']\n",
    "predictions_df['default_status'] = np.zeros(len(test))\n",
    "\n",
    "fold = StratifiedKFold(n_splits=10, shuffle= True, random_state= 42)\n",
    "i = 1\n",
    "\n",
    "for train_index, test_index in fold.split(train_data, target):\n",
    "    print('Fold number: ', i)\n",
    "\n",
    "    x_data, x_val = train_data.iloc[train_index], train_data.iloc[test_index]\n",
    "    y_data, y_val = target.iloc[train_index], target.iloc[test_index]\n",
    "    x_test = test_data\n",
    "  \n",
    "    cat = CatBoostClassifier(learning_rate=0.005, eval_metric='AUC',\n",
    "                               use_best_model=True, random_state=0, n_estimators=5000, max_depth=8)\n",
    "    cat.fit(x_data, y_data, eval_set=[(x_val, y_val)], early_stopping_rounds=300, verbose=100)\n",
    "        \n",
    "    train_pred = model.predict_proba(x_data)[:,1]\n",
    "    test_pred = model.predict_proba(x_val)[:,1]\n",
    "       \n",
    "    print('auc score on train:', roc_auc_score(y_data, train_pred))\n",
    "    print('auc score on test', roc_auc_score(y_val, test_pred))\n",
    "    auc_list.append(roc_auc_score(y_val, test_pred))\n",
    "    current_pred = model.predict_proba(x_test)[:,1]\n",
    "        \n",
    "    predictions_df['default_status']+=current_pred/fold.n_splits\n",
    "    i =+ 1\n",
    "        \n",
    "print('Mean auc score on test: ', np.mean(auc_list))  \n",
    "\n",
    "predictions_df.to_csv('submission.csv', index=False)\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
